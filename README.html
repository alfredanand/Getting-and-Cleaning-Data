<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>README</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>





</head>

<body>
<h1>README</h1>

<p>Coursera DataScience Specialisation Track</p>

<p>Getting and Cleaning Data</p>

<p>Course Project</p>

<p>Alfred Anand      20 May 2014</p>

<h2>Synopsis</h2>

<p>The purpose of this project is to collect, work with, and clean a data set. The goal is to prepare tidy data that can be used for later analysis. </p>

<p>The data used is data collected from the accelerometers from the Samsung Galaxy S smartphone. </p>

<p>A full description is available at the site where the data was obtained:<a href="http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones">http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones</a></p>

<p>Data for the project is available here: <a href="https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip">https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip</a></p>

<p>The primary script is run_analysis.R, which does the following. </p>

<ol>
<li>Merges the training and the test sets to create one data set.</li>
<li>Extracts only the measurements on the mean and standard deviation for each measurement. </li>
<li>Uses descriptive activity names to name the activities in the data set</li>
<li>Appropriately labels the data set with descriptive activity names. </li>
<li>Creates a second, independent tidy data set with the average of each variable for each activity and each subject. </li>
</ol>

<p>For details of the data definition, please refer to CodeBook.md</p>

<h2>Data Processing - A Guide to run_analysis.R</h2>

<p>The data is processed using the following steps:</p>

<ul>
<li><p>Dataset file is downloaded and unzipped</p></li>
<li><p>The following data files are loaded to a data frame of the same name:</p>

<ul>
<li>subject_train</li>
<li>X_train</li>
<li>y_train</li>
<li>subject_test</li>
<li>X_test</li>
<li>y_test</li>
</ul></li>
<li><p>Test and training data are merged as follows:</p>

<ul>
<li>test and training dataframes (X_test and X_train) are appended with a column Source to indicate if they are test or training data</li>
<li>subject_train and y_train are appended as columns to to test and training data X_train. Similarly for test X_test</li>
<li>Second columns of features data frame is converted to char</li>
<li>3 rows are added to features, to cater for the new columns created in X_train and X_test</li>
<li>New data frame X is created by merge X_train and X-test, and its column names are taken from the second column of the features dataset</li>
</ul></li>
<li><p>Measurements on the mean and standard deviation for each measurement are extracted as follows:</p>

<ul>
<li>SubX1 data frame is created from data frame X for measurements of mean, by using the indexing and grep capabilities. Similarly, SubX2 is created for standard deviations. Therefore any column name in X with the string &ldquo;mean&rdquo; or &ldquo;std&rdquo; in it will be included in SubX1 and SubX2</li>
<li>SubX data frame is created by binding SubX1, SubX2, and the last 3 columns of X, which shows Source, Subject and Activity</li>
</ul></li>
<li><p>Descriptive activity names to name the activities in the data set are set</p>

<ul>
<li>Second columns of activity_labels data frame is converted to char</li>
<li>The activity column values in the SubX dataframe is replaced with values lookedup from the activity_labels dataset. (Lookup column 1 and replace with column 2)</li>
</ul></li>
<li><p>Label the data set appropriately with descriptive activity names</p>

<ul>
<li> Not done yet!</li>
<li>Copy SubX data frame to tidydata1 dataframe, and write it out to a .csv of the same name

<ul>
<li>Creates a second, independent tidy data set with the average of each variable for each activity and each subject. </li>
</ul></li>
<li>A new data frame tidydata2 is derived by aggregating column 1 of tidydata1 data frame by subject and activity. This new data frame will have 3 columns at this point</li>
<li>A for loop appends columns to tidydata2 by aggregating columns 2 onwards of data frame tidydata1</li>
<li>tidydata1 dataframe is writen out to a .csv of the same name</li>
</ul></li>
</ul>

<h2>Information on data set</h2>

<p>The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. </p>

<p>The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. See &#39;features_info.txt&#39; for more details. </p>

<p>For each record it is provided:</p>

<ul>
<li>Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.</li>
<li>Triaxial Angular velocity from the gyroscope. </li>
<li>A 561-feature vector with time and frequency domain variables. </li>
<li>Its activity label. </li>
<li>An identifier of the subject who carried out the experiment.</li>
</ul>

<p>The dataset includes the following files:</p>

<ul>
<li>&#39;README.txt&#39;</li>
<li>&#39;features_info.txt&#39;: Shows information about the variables used on the feature vector.</li>
<li>&#39;features.txt&#39;: List of all features.</li>
<li>&#39;activity_labels.txt&#39;: Links the class labels with their activity name.</li>
<li>&#39;train/X_train.txt&#39;: Training set.</li>
<li>&#39;train/y_train.txt&#39;: Training labels.</li>
<li>&#39;test/X_test.txt&#39;: Test set.</li>
<li>&#39;test/y_test.txt&#39;: Test labels.</li>
</ul>

<p>The following files are available for the train and test data. Their descriptions are equivalent. </p>

<ul>
<li>&#39;train/subject_train.txt&#39;: Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30. </li>
<li>&#39;train/Inertial Signals/total_acc_x_train.txt&#39;: The acceleration signal from the smartphone accelerometer X axis in standard gravity units &#39;g&#39;. Every row shows a 128 element vector. The same description applies for the &#39;total_acc_x_train.txt&#39; and &#39;total_acc_z_train.txt&#39; files for the Y and Z axis. </li>
<li>&#39;train/Inertial Signals/body_acc_x_train.txt&#39;: The body acceleration signal obtained by subtracting the gravity from the total acceleration. </li>
<li>&#39;train/Inertial Signals/body_gyro_x_train.txt&#39;: The angular velocity vector measured by the gyroscope for each window sample. The units are radians/second. </li>
</ul>

<p>Notes: </p>

<ul>
<li>Features are normalized and bounded within [-1,1].</li>
<li>Each feature vector is a row on the text file.</li>
</ul>

<p>For more information about this dataset contact: <a href="mailto:activityrecognition@smartlab.ws">activityrecognition@smartlab.ws</a></p>

<p>License:
Use of this dataset in publications must be acknowledged by referencing the following publication [1] </p>

<p>[1] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012</p>

<p>This dataset is distributed AS-IS and no responsibility implied or explicit can be addressed to the authors or their institutions for its use or misuse. Any commercial use is prohibited.</p>

<p>Jorge L. Reyes-Ortiz, Alessandro Ghio, Luca Oneto, Davide Anguita. November 2012.</p>

<h3>End of Document</h3>

</body>

</html>

